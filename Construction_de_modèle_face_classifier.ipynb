{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da744a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hiba\\Desktop\\indus\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28889ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset créé avec 117 images\n",
      "                                         image_path              label\n",
      "0  eleves/aissa_lamkharbach\\IMG-20250423-WA0052.jpg  aissa_lamkharbach\n",
      "1  eleves/aissa_lamkharbach\\IMG-20250423-WA0053.jpg  aissa_lamkharbach\n",
      "2    eleves/Fatima_elfadili\\IMG-20250423-WA0001.jpg    Fatima_elfadili\n",
      "3    eleves/Fatima_elfadili\\IMG-20250423-WA0002.jpg    Fatima_elfadili\n",
      "4    eleves/Fatima_elfadili\\IMG-20250423-WA0003.jpg    Fatima_elfadili\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"eleves/\"\n",
    "\n",
    "# Créer un dataframe pour stocker les informations des images\n",
    "def create_dataset(dataset_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for person_name in os.listdir(dataset_path):\n",
    "        person_path = os.path.join(dataset_path, person_name)\n",
    "        \n",
    "        if os.path.isdir(person_path):\n",
    "            for image_name in os.listdir(person_path):\n",
    "                image_path = os.path.join(person_path, image_name)\n",
    "                \n",
    "                # Vérifier que c'est bien un fichier image\n",
    "                if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    images.append(image_path)\n",
    "                    labels.append(person_name)\n",
    "    \n",
    "    return pd.DataFrame({'image_path': images, 'label': labels})\n",
    "\n",
    "df = create_dataset(DATASET_PATH)\n",
    "print(f\"Dataset créé avec {len(df)} images\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044a53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "# Fonction de prétraitement avec détection des visages\n",
    "def preprocess_image(image_path, target_size=(160, 160)):\n",
    "    try:\n",
    "        # Charger l'image\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Détection et alignement du visage\n",
    "        boxes, probs = mtcnn.detect(img)\n",
    "        \n",
    "        if boxes is not None:\n",
    "            # Prendre la boîte avec la plus haute probabilité\n",
    "            box = boxes[np.argmax(probs)]\n",
    "            \n",
    "            # Recadrer le visage\n",
    "            face = img.crop(box)\n",
    "            face = face.resize(target_size)\n",
    "            \n",
    "            # Convertir en numpy array et normaliser\n",
    "            face_array = np.array(face).astype('float32')\n",
    "            face_array = (face_array - 127.5) / 128.0\n",
    "            \n",
    "            return face_array\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement de {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# %%\n",
    "# Appliquer le prétraitement à toutes les images\n",
    "processed_images = []\n",
    "valid_labels = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    processed_img = preprocess_image(row['image_path'])\n",
    "    if processed_img is not None:\n",
    "        processed_images.append(processed_img)\n",
    "        valid_labels.append(row['label'])\n",
    "\n",
    "# Convertir en numpy arrays\n",
    "X = np.array(processed_images)\n",
    "y = np.array(valid_labels)\n",
    "\n",
    "# Encoder les labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Sauvegarder le label encoder pour plus tard\n",
    "np.save('label_encoder.npy', label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31162e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_facenet_model():\n",
    "    # Utiliser la version PyTorch de FaceNet\n",
    "    resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "    return resnet\n",
    "\n",
    "facenet = load_facenet_model()\n",
    "\n",
    "# Fonction pour extraire les embeddings\n",
    "def get_embedding(face_pixels, model):\n",
    "    # Convertir en tensor PyTorch\n",
    "    face_tensor = torch.tensor(face_pixels.transpose(2, 0, 1)).unsqueeze(0).float().to(device)\n",
    "    \n",
    "    # Générer l'embedding\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_tensor)\n",
    "    \n",
    "    return embedding.cpu().numpy().reshape(-1)\n",
    "\n",
    "# Générer les embeddings pour toutes les images\n",
    "embeddings = np.array([get_embedding(face, facenet) for face in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd9a430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du classifieur: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['face_classifier.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    embeddings, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer un simple classifieur (SVM serait meilleur en production)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifier = SVC(kernel='linear', probability=True)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer le classifieur\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy du classifieur: {accuracy:.2f}\")\n",
    "\n",
    "# Sauvegarder le classifieur\n",
    "import joblib\n",
    "joblib.dump(classifier, 'face_classifier.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc1a858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de la reconnaissance faciale pour 3 minutes...\n",
      "Temps de détection écoulé (3 minutes)\n",
      "Détection terminée. Fichier de présence sauvegardé.\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "import time\n",
    "\n",
    "# Initialiser le moteur de synthèse vocale\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 150)  # Vitesse de parole\n",
    "\n",
    "# Configuration du temps de détection\n",
    "DETECTION_DURATION = 30  # 3 minutes en secondes\n",
    "start_time = datetime.now()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Créer le fichier CSV pour enregistrer les présences\n",
    "attendance_csv = \"attendance.csv\"\n",
    "attendance_df = pd.DataFrame(columns=['Nom', 'Prénom', 'Présent', 'Heure_detection'])\n",
    "\n",
    "# Dictionnaire pour suivre les détections\n",
    "detection_history = {label: {'detected': False, \n",
    "                            'time': None, \n",
    "                            'last_detection_time': None, \n",
    "                            'announced': False} \n",
    "                    for label in label_encoder.classes_}\n",
    "\n",
    "# Message de bienvenue\n",
    "engine.say(\"Bienvenue les élèves\")\n",
    "engine.runAndWait()\n",
    "\n",
    "print(\"Démarrage de la reconnaissance faciale pour 3 minutes...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Vérifier si le temps écoulé dépasse 3 minutes\n",
    "        elapsed_time = (datetime.now() - start_time).total_seconds()\n",
    "        if elapsed_time > DETECTION_DURATION:\n",
    "            print(\"Temps de détection écoulé (3 minutes)\")\n",
    "            # Message de fin\n",
    "            engine.say(\"Malheureusement, le temps est terminé\")\n",
    "            engine.runAndWait()\n",
    "            break\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convertir l'image pour MTCNN\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Détection des visages\n",
    "        boxes, probs = mtcnn.detect(img)\n",
    "        \n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                # Recadrer le visage\n",
    "                face = img.crop(box)\n",
    "                face = face.resize((160, 160))\n",
    "                \n",
    "                # Prétraitement\n",
    "                face_array = np.array(face).astype('float32')\n",
    "                face_array = (face_array - 127.5) / 128.0\n",
    "                \n",
    "                # Générer l'embedding\n",
    "                embedding = get_embedding(face_array, facenet)\n",
    "                \n",
    "                # Prédire la personne\n",
    "                proba = classifier.predict_proba(embedding.reshape(1, -1))\n",
    "                max_proba = np.max(proba)\n",
    "                \n",
    "                if max_proba > 0.7:  # Seuil de confiance\n",
    "                    pred_label = label_encoder.inverse_transform([np.argmax(proba)])[0]\n",
    "                    current_time = datetime.now()\n",
    "                    \n",
    "                    # Mettre à jour le temps de dernière détection\n",
    "                    detection_history[pred_label]['last_detection_time'] = current_time\n",
    "                    \n",
    "                    # Si c'est une nouvelle détection\n",
    "                    if not detection_history[pred_label]['detected']:\n",
    "                        detection_history[pred_label]['detected'] = True\n",
    "                        detection_history[pred_label]['time'] = current_time\n",
    "                    \n",
    "                    # Vérifier si 2 secondes se sont écoulées depuis la détection initiale\n",
    "                    if (not detection_history[pred_label]['announced'] and \n",
    "                        (current_time - detection_history[pred_label]['time']).total_seconds() >= 2):\n",
    "                        nom, prenom = pred_label.split('_')\n",
    "                        engine.say(f\"Merci {nom} {prenom}\")\n",
    "                        engine.runAndWait()\n",
    "                        detection_history[pred_label]['announced'] = True\n",
    "                    \n",
    "                    # Dessiner le rectangle et le nom\n",
    "                    box = box.astype(int)\n",
    "                    cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, pred_label, (box[0], box[1]-10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    # Visage inconnu détecté\n",
    "                    box = box.astype(int)\n",
    "                    cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, \"Inconnu\", (box[0], box[1]-10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                    \n",
    "                \n",
    "        \n",
    "        # Afficher le résultat et le temps restant\n",
    "        remaining_time = max(0, DETECTION_DURATION - elapsed_time)\n",
    "        time_text = f\"Temps restant: {int(remaining_time // 60)}:{int(remaining_time % 60):02d}\"\n",
    "        cv2.putText(frame, time_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.imshow('Reconnaissance Faciale', frame)\n",
    "        \n",
    "        # Quitter avec la touche 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # Finaliser l'enregistrement des présences\n",
    "    current_time = datetime.now()\n",
    "    \n",
    "    # Créer le dataframe final\n",
    "    final_attendance = []\n",
    "    \n",
    "    for label in detection_history:\n",
    "        nom, prenom = label.split('_')\n",
    "        if detection_history[label]['detected']:\n",
    "            status = \"Présent\"\n",
    "            detection_time = detection_history[label]['time']\n",
    "        else:\n",
    "            status = \"Absent\"\n",
    "            detection_time = current_time\n",
    "        \n",
    "        final_attendance.append({\n",
    "            'Nom': nom,\n",
    "            'Prénom': prenom,\n",
    "            'Présent': status,\n",
    "            'Heure_detection': detection_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        })\n",
    "    \n",
    "    # Créer le DataFrame final\n",
    "    attendance_df = pd.DataFrame(final_attendance)\n",
    "    \n",
    "    # Sauvegarder le fichier CSV\n",
    "    attendance_df.to_csv(attendance_csv, index=False)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Détection terminée. Fichier de présence sauvegardé.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
